from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import xgboost as xgb
import numpy as np
from pydantic import BaseModel
from sklearn.preprocessing import MinMaxScaler
import pickle
from neo4j import GraphDatabase
import pandas as pd


# start server
# poetry run uvicorn app:app --host 0.0.0.0 --port 8000 --reload
# DBæŽ¥ç¶šå‡¦ç†
# Neo4jã«æŽ¥ç¶š
uri = "bolt://localhost:7687"
user = "neo4j"
password = "abcd7890"


# curl -X 'POST' \
#   'http://127.0.0.1:8000/predict/' \
#   -H 'Content-Type: application/json' \
#   -d '{
#     "food1_id": "garlic",
#     "food2_id": "garden_tomato"
#   }'

# ãƒ‰ãƒ©ã‚¤ãƒã‚’ä½œæˆ
driver = GraphDatabase.driver(uri, auth=(user, password))
# Initialize FastAPI app
app = FastAPI()
# CORSã®è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ã™ã¹ã¦ã®ã‚ªãƒªã‚¸ãƒ³ã‚’è¨±å¯ï¼ˆæœ¬ç•ªã§ã¯ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã¿ã‚’æŒ‡å®šï¼‰
    allow_credentials=True,
    allow_methods=["*"],  # ã™ã¹ã¦ã®HTTPãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¨±å¯
    allow_headers=["*"],  # ã™ã¹ã¦ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨±å¯
)

# Load the saved XGBoost model
model = xgb.XGBClassifier()
model.load_model("../data/unusual_paring_model.json")

# Load the saved scaler
with open("../data/scaler_X.pkl", "rb") as f:
    scalerX = pickle.load(f)

with open("../data/scaler_y.pkl", "rb") as f:
    scalerY = pickle.load(f)

# Define request schema
class FoodPairRequest(BaseModel):
    food1_id: str
    food2_id: str
    
# Define Neo4j queries
def find_score(tx, id1, id2):
    query4 = """
        MATCH (f1:Food {id: $id1})
        MATCH (f2:Food {id: $id2})
        OPTIONAL MATCH (f1)-[r:USED_TOGETHER]->(f2)
        OPTIONAL MATCH (f1)-[:SCENTED]->(a:Aroma)<-[:SCENTED]-(f2)
        RETURN f1.id AS food1_id, 
               f2.id AS food2_id, 
               SUM(COALESCE(r.frequency, 0)) AS frequency,
               COUNT(a) AS shared_aromas,
               f1.popularity AS food1_popularity,
               f2.popularity AS food2_popularity,
               f1.pagerank AS food1_pagerank, 
               f2.pagerank AS food2_pagerank,
               gds.similarity.cosine(f1.word_vector, f2.word_vector) as word_similarity, 
               gds.similarity.overlap(f1.flavor_vector, f2.flavor_vector) as flavor_similarity

    """
    result = tx.run(query4, id1=id1, id2=id2)
    data = result.data()
    
    if data:
        return data[0]  # 1ã¤ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿å–å¾—
    return None

# API route for prediction
@app.post("/predict/")
def predict(food_pair: FoodPairRequest):
    Xcolumns = ["shared_aromas","food1_popularity","food2_popularity","food1_pagerank","food2_pagerank", "word_similarity", "flavor_similarity"]

    # Neo4j ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
    with driver.session() as session:
        result = session.execute_read(find_score, food_pair.food1_id, food_pair.food2_id)
    
    # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®å‡¦ç†
    if not result:
        return {"error": "Food pair not found in the database"}
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–ã—ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    result_df = pd.DataFrame([result])  # 1è¡Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã™ã‚‹
    input_scaled = scalerX.transform(result_df[Xcolumns])

    # äºˆæ¸¬å®Ÿè¡Œ
    prediction = model.predict(input_scaled)[0]
    prediction_proba = model.predict_proba(input_scaled)[0][1]  # "Unusual" ã§ã‚ã‚‹ç¢ºçŽ‡

    return {
        "usual_pairing": bool(prediction),  # ðŸ”¹ numpyåž‹ã‹ã‚‰ Python ã® bool ã«å¤‰æ›
        "probability": float(prediction_proba)  # ðŸ”¹ numpy.float32 ã‹ã‚‰ Python ã® float ã«å¤‰æ›
    }

# API root
@app.get("/")
def root():
    return {"message": "Food Pairing Prediction API is running!"}
