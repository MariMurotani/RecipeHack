{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "from collections import Counter\n",
    "import mysql.connector\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/fbyxhbrx6h3_4s4m15x3bly00000gn/T/ipykernel_2231/890882507.py:3: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  gpt_client = OpenAI(\n"
     ]
    }
   ],
   "source": [
    "# ChatGPTを使うのでAPIキーを設定\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "gpt_client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB接続処理\n",
    "# Neo4jに接続\n",
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"abcd7890\"\n",
    "\n",
    "# ドライバを作成\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPTを使って意味のある文章を生成する\n",
    "def get_gpt_result(prompt):\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip(\"\\n\")\n",
    "\n",
    "\n",
    "# レシピから情報を抽出する\n",
    "def extract_ingredient_name(text):\n",
    "    prompt = f\"\"\"\n",
    "Extract the ingredient name from the text below. Remove any quantities, units, or modifiers. \n",
    "Convert multiple forms of the same ingredient into its singular form. \n",
    "Replace specific brand names, product names, or unique ingredient names (e.g., Epsom salt) with simple, general names (e.g., salt).\n",
    "\n",
    "Input:\n",
    "{text}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "    return get_gpt_result(prompt)\n",
    "\n",
    "# 作業時間をminの揃える\n",
    "def extract_minutes(text):\n",
    "    prompt = f\"\"\"\n",
    "Convert a given total_time string (e.g., \"1 hr 45 min\") into the total time in minutes. Ensure to handle cases with both \"hr\" and \"min\" or only \"hr\" or \"min\". Return the result as an integer representing the total minutes.\n",
    "And remove any other information, including the word \"minutes\".\n",
    "\n",
    "Input:\n",
    "{text}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "    return get_gpt_result(prompt)[0]\n",
    "\n",
    "# 作業時間を推測する\n",
    "def guess_total_minutes(text, ingredients):\n",
    "    prompt = f\"\"\"\n",
    "Estimate the total time required to complete the task based on its title and ingredients and answer in minutes, return integer value.\n",
    "\n",
    "Input:\n",
    "title: {text}\n",
    "ingredients: {ingredients.join(\", \")}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "    return get_gpt_result(prompt)[0]\n",
    "\n",
    "# webページから情報を抽出する\n",
    "def fetch_webpage_content(url):\n",
    "    \"\"\"\n",
    "    Fetch HTML content from the URL and extract visible text.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    # Extract visible text from the webpage\n",
    "    return soup.get_text()\n",
    "\n",
    "# webページから\n",
    "def extract_ingredient_names_from_url(url):\n",
    "    \"\"\"\n",
    "    Use LangChain to extract ingredient names from the given URL's content.\n",
    "    \"\"\"\n",
    "    # Step 1: Fetch webpage content\n",
    "    content = fetch_webpage_content(url)\n",
    "    \n",
    "    # Step 2: Define the prompt template\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"content\"],\n",
    "        template=\"\"\"\n",
    "        I want you to act as an ingredient extractor. Given the text content of a webpage, \n",
    "        extract and return a clean, deduplicated array of ingredient names mentioned in the content. \n",
    "        Do not include unrelated text or additional information. \n",
    "        Convert plural forms of ingredients into their singular form.\n",
    "        If no ingredients are found, return an empty array.\n",
    "\n",
    "        Here is the text content: \n",
    "        {content}\n",
    "        \n",
    "        Output:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Step 3: Generate the prompt\n",
    "    llm = OpenAI(model_name=\"gpt-4\")  # Or \"gpt-3.5-turbo\" for faster response\n",
    "    prompt = prompt_template.format(content=content)\n",
    "    \n",
    "    # Step 4: Get LLM response\n",
    "    response = llm(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストフォーマットの指定\n",
    "def format_text(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = text.replace('(', '_')\n",
    "    text = text.replace(')', '_')\n",
    "    text = text.replace(\"/\", '_')\n",
    "    text = text.replace(\";\", '_')\n",
    "    text = text.replace(\":\", '_')\n",
    "    text = text.replace(\"&\", '_')\n",
    "    text = text.replace(\"[\", '')\n",
    "    text = text.replace(\"]\", '')    \n",
    "    text = text.replace('\"', '')\n",
    "    text = text.replace('<', '')\n",
    "    text = text.replace('>', '')\n",
    "    text = text.replace(', ', ',')\n",
    "    text = text.replace('.', '')\n",
    "    text = text.replace(',', '_')\n",
    "    text = text.replace('-', ' ')\n",
    "    text = text.replace(' ', '_')\n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace('%', '')\n",
    "    text = text.replace(\"'\", '')\n",
    "    text = text.replace(\"/t\", '')\n",
    "    text = text.replace(\"\\\\\", '')\n",
    "    text = text.replace(\"é\", '')\n",
    "    text = text.replace(\"ç\", '')\n",
    "    text = text.replace(\"+\", '')\n",
    "    text = text.replace(\"`\", '')\n",
    "    text = text.replace(\"`\", '')\n",
    "    text = text.replace(\"`\", '')\n",
    "    text = text.replace(\"`\", '')\n",
    "    text = text.replace(\"ã\", '')\n",
    "    text = text.replace(\"â\", '')\n",
    "    text = text.replace(\"ƒ\", '')\n",
    "    text = text.replace(\"€\", '')\n",
    "    text = text.replace('”', '')\n",
    "    text = text.replace('`', '')\n",
    "    text = text.replace('!', '')\n",
    "    text = text.replace('|', '')\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\"\\r\", \"\")\n",
    "    text = re.sub(r'\\s+', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def escape_sql_string(text):\n",
    "    text = text.rstrip(\"\\\\\")\n",
    "    return text.replace(\"'\", \"''\")\n",
    "\n",
    "def clean_title(text):\n",
    "    text = text.replace(\"ã\", '')\n",
    "    text = text.replace(\"â\", '')\n",
    "    text = text.replace(\"ƒ\", '')\n",
    "    text = text.replace(\"€\", '')\n",
    "    text = text.replace(\"é\", '')\n",
    "    text = text.replace(\"ç\", '')\n",
    "    # UTF-8にエンコードし、デコード時にエラーを無視して文字化けを削除\n",
    "    text = text.encode('utf-8', 'replace').decode('utf-8', 'ignore')\n",
    "    return clean_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークン化して保存する\n",
    "def tokenize_save(key_name, sentences):\n",
    "    # NumPyの配列に変換\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        if sentence is None:\n",
    "            continue\n",
    "        \n",
    "        if isinstance(sentence, list):\n",
    "            sentence = \" \".join(sentence)\n",
    "            \n",
    "        # 小文字化し、特殊文字や句読点を削除してトークン化\n",
    "        words = re.findall(r'\\b[a-zA-Z0-9_]+\\b', sentence.lower())\n",
    "        tokens.append(words)\n",
    "        \n",
    "    np_sentences = np.array(tokens, dtype=object)\n",
    "\n",
    "    # NumPyの配列をdumpして保存\n",
    "    np.save(f\"../datas/word2_vec/{key_name}.npy\", np_sentences)\n",
    "    with open(f\"../datas/word2_vec/{key_name}.txt\", 'w') as f:\n",
    "        json.dump(tokens, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_food(tx, search_term):\n",
    "    find_food_query = \"\"\"\n",
    "    CALL db.index.fulltext.queryNodes(\"food_sub_index_text_search\", $search_term)\n",
    "    YIELD node, score\n",
    "    ORDER BY score DESC, size(node.name)\n",
    "    LIMIT 1\n",
    "    RETURN node.id as node_id, node.name as node_name, node.flavor_vector as flavor_vector, node.word_vector as word_vector, score    \n",
    "    \"\"\"\n",
    "    return tx.run(find_food_query, search_term=search_term).data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_INPUT_PATH = \"../data/json_recipes/\"\n",
    "JSON_OUTPUT_PATH = \"../data/formatted_json_recipe.json\"\n",
    "def get_json_files(file):\n",
    "    json_files = os.listdir(file)\n",
    "    return json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802\n"
     ]
    }
   ],
   "source": [
    "unique_recipes = {}\n",
    "\n",
    "for file in get_json_files(JSON_INPUT_PATH):\n",
    "    with open(f\"{JSON_INPUT_PATH}{file}\") as f:\n",
    "        json_data = json.load(f)\n",
    "        if not 'recipes_results' in json_data or json_data['recipes_results'] is None:\n",
    "            continue\n",
    "        \n",
    "        for item in json_data[\"recipes_results\"]:\n",
    "            unique_recipes[item['title']] = item\n",
    "            \n",
    "print(len(unique_recipes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n"
     ]
    }
   ],
   "source": [
    "recipes = {}\n",
    "for key, item in unique_recipes.items():\n",
    "    if not 'ingredients' in item or item['ingredients'] is None:\n",
    "        continue\n",
    "\n",
    "    extracted_ingredient = extract_ingredient_name_from_url(item[\"link\"])\n",
    "    print(extracted_ingredient)\n",
    "    \n",
    "    ingredients = []\n",
    "    for ingri in item['ingredients']:\n",
    "        if ingredients is None:\n",
    "            continue\n",
    "        ingredients.append(extract_ingredient_name(ingri))\n",
    "    \n",
    "    total_time = \"\"\n",
    "    if \"total_time\" in item:\n",
    "        total_time = extract_minutes(item['total_time'])\n",
    "    else:\n",
    "        total_time = guess_total_minutes(item['title'], ingredients)\n",
    "    \n",
    "    rating = \"\"\n",
    "    if \"rating\" in item:\n",
    "        rating = item['rating']\n",
    "    \n",
    "    reviews = \"\"\n",
    "    if \"reviews\" in item:\n",
    "        reviews = item['reviews']\n",
    "    else:\n",
    "        reviews = 0\n",
    "        \n",
    "    title = clean_title(item['title'])\n",
    "    json_input = {\n",
    "        \"name\": title,\n",
    "        \"rating\": rating,\n",
    "        \"reviews\": reviews,\n",
    "        \"total_time\": total_time,\n",
    "        \"ingredients\": ingredients\n",
    "    }\n",
    "    recipes[title] = json_input\n",
    "    break\n",
    "\n",
    "#with open(f\"../data/{JSON_OUTPUT_PATH}\", 'w') as f2:\n",
    "#    json.dump(recipes, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recipe-qa-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
